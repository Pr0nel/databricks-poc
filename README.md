# Lakehouse POC: Hybrid Data Architecture

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Apache Spark 3.5.0](https://img.shields.io/badge/apache%20spark-3.5.0-orange.svg)](https://spark.apache.org/)
[![Delta Lake 3.1.0](https://img.shields.io/badge/delta%20lake-3.1.0-red.svg)](https://delta.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## üìã Tabla de Contenidos

- [Descripci√≥n](#descripci√≥n)
- [Arquitectura](#arquitectura)
- [Stack Tecnol√≥gico](#stack-tecnol√≥gico)
- [Requisitos Previos](#requisitos-previos)
- [Instalaci√≥n](#instalaci√≥n)
- [Configuraci√≥n](#configuraci√≥n)
- [Uso](#uso)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Etapas de Implementaci√≥n](#etapas-de-implementaci√≥n)
- [Troubleshooting](#troubleshooting)
- [M√©tricas y Monitoreo](#m√©tricas-y-monitoreo)
- [Contribuciones](#contribuciones)
- [Recursos Adicionales](#recursos-adicionales)
- [Licencia](#licencia)
- [Autor](#autor)
- [Pr√≥ximos Pasos](#pr√≥ximos-pasos)
- [Changelog](#changelog)

---

## üìñ Descripci√≥n

**Lakehouse POC** es una prueba de concepto que demuestra una arquitectura **data lakehouse h√≠brida** local + cloud, combinando:

- **Streaming en tiempo real** con Apache Kafka
- **Delta Lake** para ACID transactions y time travel
- **Arquitectura Medallion** (Bronze -> Silver -> Gold)
- **Cloud Storage** (AWS S3)
- **Databricks Integration** con Unity Catalog y Auto Loader
- **Gobernanza de datos** y esquemas evolucionables

**Prop√≥sito:** Demostrar patrones enterprise reales de ingesta, transformaci√≥n y gobernanza de datos.

---

## üèóÔ∏è Arquitectura

### Diagrama General

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       LAKEHOUSE H√çBRIDO                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  CAPA 1: INGESTA (Docker Local - Streaming)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Kafka (localhost:9092) -> Spark Consumer -> Delta LOCAL ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Formato: JSON                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Frecuencia: Micro-batches (5s)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              |                                ‚îÇ
‚îÇ                              v                                ‚îÇ
‚îÇ  CAPA 2: ALMACENAMIENTO (Batch - Persistencia)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Delta LOCAL -> S3 Parquet (particionado por fecha)      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Formato: Parquet                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Particionado: ingestion_date                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              |                                ‚îÇ
‚îÇ                              v                                ‚îÇ
‚îÇ  CAPA 3: TRANSFORMACI√ìN (Databricks Cloud)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Auto Loader S3 -> Bronze -> Silver -> Gold              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Schema Evolution autom√°tica                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ Unity Catalog (gobernanza)                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è Stack Tecnol√≥gico

| Componente | Versi√≥n | Prop√≥sito |
|-----------|---------|----------|
| **Kafka** | 7.4.0 | Streaming de eventos |
| **Spark** | 3.5.0 | Procesamiento distribuido |
| **Delta Lake** | 3.1.0 | Data lakehouse (ACID, time travel) |
| **Python** | 3.9+ | Orquestaci√≥n y l√≥gica |
| **Docker** | 24.0+ | Contenedorizaci√≥n |
| **AWS S3** | - | Cloud storage |
| **Databricks** | Serverless | Data platform cloud |

---

## üì¶ Requisitos Previos

### Local

- Python 3.9+
- Docker y Docker Compose 24.0+
- Java 11+ (para Spark)
- pip (gestor de paquetes Python)

### AWS

- Cuenta AWS con permisos S3
- IAM user con credenciales (Access Key + Secret Key)

### Databricks

- Workspace Databricks (trial gratuito disponible)
- PAT token (Personal Access Token)

---

## üöÄ Instalaci√≥n

### 1. Clonar Repositorio

```bash
git clone https://github.com/Pr0nel/databricks-poc.git
cd databricks-poc
```

### 2. Crear Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Variables de Entorno

```bash
# .env
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_S3_BUCKET=your-lakehouse-poc-bucket
KAFKA_BOOTSTRAP_SERVERS=localhost:
KAFKA_TOPIC=test-events
DATABRICKS_HOST=https://your-workspace.databricks.com
DATABRICKS_TOKEN=your_pat_token
```

---

## ‚öôÔ∏è Configuraci√≥n

### Validar Infraestructura

```bash
# Verificar Python y dependencias
python3 config/settings.py

# Verificar logging
python3 config/logging_config.py

# Verificar Docker
scripts/docker-helpers.sh status
```

### Levantar Docker (Kafka + Zookeeper)

```bash
# Desarrollo (sin persistencia)
scripts/docker-helpers.sh dev-up

# Verificar que est√° listo
scripts/docker-helpers.sh status

# Testear conexi√≥n
scripts/docker-helpers.sh test-kafka
```

---

## üíª Uso

### Ejecuci√≥n Completa del Pipeline

```bash
# Aseg√∫rate de que Docker est√° activo
scripts/docker-helpers.sh dev-up

# Ejecutar todo
python3 run_pipeline.py
```

**Resultado esperado:**
```
===================================================================
    LAKEHOUSE POC - PIPELINE COMPLETO
===================================================================

[PASO 1/5] Setup S3 Structure
    Setup S3 structure (crear carpetas bronze/silver/gold) - EXITOSO

[PASO 2/5] Kafka Producer
    Kafka Producer (generar 50 eventos) - EXITOSO
    Producci√≥n completada
    Exitosos: 50/50
    Fallidos: 0/50

[PASO 3/5] Spark Streaming Consumer
    Streaming: Kafka -> Delta LOCAL (120 segundos) - EXITOSO
    Filas en Delta: 50

[PASO 4/5] Spark Batch Writer
    Batch: Delta LOCAL -> S3 Parquet - EXITOSO
    Datos escritos a S3 exitosamente

[PASO 5/5] Spark S3 Validator
    Validation: S3 Quality Checks - EXITOSO
    Total de filas: 50
    Data Quality Checks completados

===================================================================
    PIPELINE COMPLETADO EXITOSAMENTE
===================================================================
```

### Ejecuci√≥n de Componentes Individuales

```bash
# Solo Producer (generar eventos)
python3 scripts/kafka_producer.py

# Solo Consumer (ingestar a Delta)
python3 pyspark-jobs/01_spark_kafka_consumer.py

# Solo Batch (persistir a S3)
python3 pyspark-jobs/02_spark_delta_to_s3.py

# Solo Validaci√≥n
python3 pyspark-jobs/03_spark_s3_validator.py
```

### Docker Commands

```bash
# Levantar
scripts/docker-helpers.sh dev-up

# Ver estado
scripts/docker-helpers.sh status

# Ver logs de Kafka
scripts/docker-helpers.sh logs-kafka

# Acceder a shell de Kafka
scripts/docker-helpers.sh shell-kafka

# Reset completo (limpia todo)
scripts/docker-helpers.sh reset-dev

# Detener
scripts/docker-helpers.sh stop

# Ver todos los comandos
scripts/docker-helpers.sh help
```

---

## üìÅ Estructura del Proyecto

```
databricks-poc/
‚îÇ
‚îú‚îÄ config/                          <- Configuraci√≥n centralizada
‚îÇ  ‚îú‚îÄ config.yaml                   (vars de entorno)
‚îÇ  ‚îú‚îÄ settings.py                   (parser de config)
‚îÇ  ‚îî‚îÄ logging_config.py             (setup de logging)
‚îÇ
‚îú‚îÄ utils/                           <- M√≥dulos reutilizables
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ data_validators.py            (validaciones comunes)
‚îÇ  ‚îú‚îÄ encoding_utils.py             (MessageEncoder UTF-8)
‚îÇ  ‚îú‚îÄ health_check.py               (health checks)
‚îÇ  ‚îú‚îÄ retry_logic.py                (pol√≠ticas de retry)
‚îÇ  ‚îú‚îÄ schema_definitions.py         (schemas centralizados)
‚îÇ  ‚îî‚îÄ spark_utils.py                (factory SparkSession)
‚îÇ
‚îú‚îÄ scripts/                         <- Herramientas de desarrollo
‚îÇ  ‚îú‚îÄ kafka_producer.py             (genera eventos a Kafka)
‚îÇ  ‚îú‚îÄ setup_s3.py                   (estructura S3)
‚îÇ  ‚îî‚îÄ docker-helpers.sh             (CLI Docker)
‚îÇ
‚îú‚îÄ pyspark-jobs/                    <- Jobs de Spark
‚îÇ  ‚îú‚îÄ 01_spark_kafka_consumer.py    (Kafka -> Delta) Streaming
‚îÇ  ‚îú‚îÄ 02_spark_write_delta_s3.py    (Delta -> S3) Batch
‚îÇ  ‚îî‚îÄ 03_spark_s3_validator.py      (Validar S3) Quality Checks
‚îÇ
‚îú‚îÄ notebooks/                       <- Notebooks Databricks
‚îÇ  ‚îú‚îÄ 01_auto_loader_setup.py
‚îÇ  ‚îú‚îÄ 02_auto_loader_bronze.py
‚îÇ  ‚îî‚îÄ 03_schema_evolution_test.py
‚îÇ
‚îú‚îÄ docker/
‚îÇ  ‚îú‚îÄ docker-compose.yml            (config principal)
‚îÇ  ‚îî‚îÄ docker-compose.dev.yml        (override desarrollo)
‚îÇ
‚îú‚îÄ logs/                            <- Logs rotados
‚îÇ  ‚îú‚îÄ kafka_producer.log
‚îÇ  ‚îú‚îÄ orchestrator.log
‚îÇ  ‚îú‚îÄ setup_s3.log
‚îÇ  ‚îú‚îÄ spark_kafka_consumer.log
‚îÇ  ‚îú‚îÄ spark_write_delta_s3.log
‚îÇ  ‚îî‚îÄ spark_s3_validator.log
‚îÇ
‚îú‚îÄ spark_checkpoints/               <- Checkpoints de Spark
‚îÇ  ‚îú‚îÄ delta_consumer/
‚îÇ  ‚îî‚îÄ s3_consumer/
‚îÇ
‚îú‚îÄ delta_tables/                    <- Delta local (temporal)
‚îÇ  ‚îî‚îÄ events_raw/
‚îÇ
‚îú‚îÄ requirements.txt                 <- Dependencias Python
‚îú‚îÄ .env                             <- Template de variables
‚îú‚îÄ .gitignore                       <- Template de archivos y carpetas no subidos a github
‚îú‚îÄ LICENSE                          <- Licencia
‚îú‚îÄ README.md                        <- Este archivo
‚îî‚îÄ run_pipeline.py                  <- Orquestador principal
```

---

## üìä Etapas de Implementaci√≥n

### ETAPA 0: Validaci√≥n de Infraestructura
Verificar que todos los servicios est√°n disponibles:
- Databricks Serverless
- AWS S3 + IAM
- Docker + Kafka
- Spark local + Delta

### ETAPA 1: Setup Inicial
Preparar c√≥digo base sin ejecutar:
- Docker Compose
- AWS S3 config
- Databricks setup

### ETAPA 2: Docker Kafka
Levantar Kafka y validar:
- Kafka + Zookeeper cluster
- Producer de eventos
- Creaci√≥n de Kafka topics
- Health checks

### ETAPA 3: Spark Streaming
Implementar pipeline local:
- Kafka Consumer
- JSON Parsing
- Escritura de Delta (local)
- Escritura parquet en S3
- Validaciones

### ETAPA 4: Databricks Auto Loader
Implementar transformaciones cloud:
- Auto Loader setup
- Schema evolution
- Unity Catalog

### ETAPA 5: Transformaciones Medallion
Implementar capas Silver + Gold:
- Bronze -> Silver (limpieza)
- Silver -> Gold (agregaciones)
- Lineage y gobernanza

### ETAPA 6: Documentaci√≥n
Notebooks y docs finales

---

## üêõ Troubleshooting

### Kafka no responde

```bash
# Reset completo de Docker
scripts/docker-helpers.sh reset-dev

# Esperar 20 segundos

# Verificar
scripts/docker-helpers.sh test-kafka
```

### Error de credenciales AWS

```bash
# Verificar que .env est√° configurado
cat .env

# Validar acceso S3
python3 scripts/setup_s3.py
```

### Spark falla con timeout

Aumentar timeouts en config.yaml
    - spark_consumer: 180 -> 300 (segundos)

---

## üìà M√©tricas y Monitoreo

Todos los jobs generan logs detallados en `logs/`:

```bash
# Ver logs en tiempo real
tail -f logs/spark_kafka_consumer.log

# Ver √∫ltimo 50 eventos
tail -50 logs/orchestrator.log

# Buscar errores
grep ERROR logs/*.log
```

---

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Para cambios principales:

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit cambios (`git commit -m 'Agregar mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Open Pull Request

---

## üìö Recursos Adicionales

- [Delta Lake Documentation](https://docs.delta.io/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Databricks Unity Catalog](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)
- [AWS S3 Guide](https://docs.aws.amazon.com/s3/)
- [Kafka Documentation](https://kafka.apache.org/documentation/)

---

## üìù Licencia

Este proyecto est√° bajo la Licencia MIT - ver archivo [LICENSE](LICENSE) para detalles. Sino, en <https://opensource.org/license/mit>.

---

## ‚úçÔ∏è Autor

**[Pablo Ratache Rojas]** - Data Engineer

- GitHub: [@Pr0nel](https://github.com/Pr0nel)
- LinkedIn: [Pablo Ratache](www.linkedin.com/in/pablo-ratache-rojas-9a9602140)
- Portfolio: [Pablo's Portfolio](https://pr0nel.github.io/cv_pablo_ratache/)

---

## üéØ Pr√≥ximos Pasos

- [ ] Agregar tests unitarios
- [ ] Documentar transformaciones de negocios
- [ ] Configurar CI/CD con GitHub Actions

---

## Changelog

### v1.0.0

**√öltima actualizaci√≥n:** Noviembre 2025